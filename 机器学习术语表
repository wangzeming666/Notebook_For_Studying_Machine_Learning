Fastbook 第一章到第五章 简洁术语表

---

     **第一章：什么是机器学习？**
- **机器学习 (Machine Learning)**：从数据中学习模式以做出预测。
- **监督学习 (Supervised Learning)**：训练数据有目标标签。
- **无监督学习 (Unsupervised Learning)**：训练数据无目标标签。
- **训练集 (Training Set)**：用于训练模型的数据。
- **验证集 (Validation Set)**：用于评估模型性能的数据。

---

     **第二章：从模型到部署**
- **模型 (Model)**：数学函数，用于预测。
- **参数 (Parameters)**：模型训练中学习的权重。
- **损失函数 (Loss Function)**：衡量预测与真实值的差异。
  - 示例：均方误差 (MSE)。
- **优化器 (Optimizer)**：调整参数以最小化损失。
  - 示例：随机梯度下降 (SGD)。
- **学习率 (Learning Rate)**：控制参数调整的步幅大小。

---

     **第三章：第一个模型**
- **线性模型 (Linear Model)**：输入的线性组合作为输出。
  - 公式：\(y = wx + b\)。
- **回归 (Regression)**：预测连续值。
- **分类 (Classification)**：预测离散类别。
- **激活函数 (Activation Function)**：引入非线性，常用 ReLU 或 Sigmoid。

---

     **第四章：梯度下降**
- **梯度下降 (Gradient Descent)**：通过梯度调整参数以最小化损失。
- **梯度 (Gradient)**：损失函数对参数的导数。
- **学习率调度 (Learning Rate Scheduler)**：动态调整学习率。
- **过拟合 (Overfitting)**：模型在训练集表现好但验证集表现差。
- **欠拟合 (Underfitting)**：模型在训练集和验证集表现都不好。
- **反向传播 (Backpropagation)**：通过反向传播误差计算梯度。

---

     **第五章：更复杂的模型**
- **交叉熵损失 (Cross-Entropy Loss)**：分类任务中衡量预测分布与真实分布差异的损失函数。
- **Softmax**：将 logits 转换为概率分布。
- **验证损失 (Validation Loss)**：验证集上的损失。
- **迁移学习 (Transfer Learning)**：将预训练模型的知识迁移到新任务。
- **Fine-Tuning**：对预训练模型进行微调。
- **最大似然估计 (MLE)**：通过最大化数据的似然函数估计模型参数。

---

     **补充说明**
- **Batch Size**：每次训练中使用的数据样本数。
- **Epoch**：遍历整个训练集一次。
- **关键联系**：
  - 激活函数使模型具有非线性。
  - 梯度下降依赖损失函数和梯度。
  - 学习率调度器提高训练效率。
